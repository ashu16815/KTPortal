import type { WeeklySubmissionDTO } from '@/types'

export interface TowerReportInput {
  name: string
  group: string
  phase: string
  twgScore: number | null
  tcsScore: number | null
  ragStatus: string | null
  overdueActions: number
  openRaidds: number
  narrative: string | null
  risks: string[]
  blockers: string[]
}

export interface ProgrammeReportInput {
  weekEnding: string
  totalTowers: number
  ragCounts: { RED: number; AMBER: number; GREEN: number }
  towers: TowerReportInput[]
  topRaidds: Array<{ type: string; title: string; impact: string; towerName: string }>
  overdueActions: Array<{ title: string; towerName: string; priority: string }>
  atRiskMilestones: Array<{ name: string; towerName: string; status: string }>
  pulseComments: Array<{ track: string; comment: string; towerName: string }>
}

export interface ProgrammeReport {
  summary: string
  workingWell: string
  notWorking: string
  commonRisks: string
  priorityActions: string
  forwardActions: string
}

export interface AIProvider {
  generateSummary(submission: Partial<WeeklySubmissionDTO>, towerName: string): Promise<string>
  generateProgrammeReport(data: ProgrammeReportInput): Promise<ProgrammeReport>
}

class StubAIProvider implements AIProvider {
  async generateSummary(submission: Partial<WeeklySubmissionDTO>, towerName: string): Promise<string> {
    const rag = submission.ragStatus ?? 'AMBER'
    const score = submission.totalScore ?? 0
    return `[AI STUB] KT Status for ${towerName}: Overall health is ${rag} with a score of ${score}/100. ` +
      `Progress is ${submission.progressScore ?? 0}/100, coverage ${submission.coverageScore ?? 0}/100, ` +
      `confidence ${submission.confidenceScore ?? 0}/100. ` +
      `Key narrative: ${submission.narrative ?? 'No narrative provided.'} ` +
      `This summary was generated by the stub AI provider. Set AZURE_OPENAI_KEY to enable real summaries.`
  }

  async generateProgrammeReport(data: ProgrammeReportInput): Promise<ProgrammeReport> {
    const { totalTowers, ragCounts, towers } = data
    const redTowers = towers.filter(t => t.ragStatus === 'RED').map(t => t.name).join(', ')
    return {
      summary: `[AI STUB] Programme Health: ${totalTowers} towers active. RAG: ${ragCounts.GREEN} GREEN, ${ragCounts.AMBER} AMBER, ${ragCounts.RED} RED. Set AZURE_OPENAI_KEY for real AI analysis.`,
      workingWell: '[AI STUB] Multiple towers are progressing through KT phases with consistent scoring from both TWG and TCS teams.',
      notWorking: redTowers ? `[AI STUB] Towers requiring immediate attention: ${redTowers}. Review blockers and escalate as needed.` : '[AI STUB] No critical blockers identified at programme level.',
      commonRisks: '[AI STUB] Cross-tower risks include knowledge concentration, timeline pressure, and resource availability. Review RAIDD log for details.',
      priorityActions: '[AI STUB] 1. Clear all overdue actions. 2. Escalate RED tower issues to steering committee. 3. Ensure weekly submissions are up to date.',
      forwardActions: '[AI STUB] Continue weekly cadence, monitor variance between TWG and TCS scores, and progress milestone completion. Real AI analysis available when AZURE_OPENAI_KEY is configured.',
    }
  }
}

class AzureOpenAIProvider implements AIProvider {
  private apiKey: string
  private endpoint: string
  private deploymentName: string
  private apiVersion: string

  constructor() {
    // Support both AZURE_OPENAI_API_KEY (new) and AZURE_OPENAI_KEY (legacy)
    this.apiKey = (process.env.AZURE_OPENAI_API_KEY ?? process.env.AZURE_OPENAI_KEY)!
    this.endpoint = process.env.AZURE_OPENAI_ENDPOINT!.replace(/\/$/, '')
    this.deploymentName = process.env.AZURE_OPENAI_DEPLOYMENT_GPT5 ?? process.env.AZURE_OPENAI_DEPLOYMENT ?? 'gpt-4o'
    this.apiVersion = process.env.AZURE_OPENAI_API_VERSION ?? '2024-10-01-preview'
  }

  private get url() {
    return `${this.endpoint}/openai/deployments/${this.deploymentName}/chat/completions?api-version=${this.apiVersion}`
  }

  // gpt-5-mini is a reasoning model: uses max_completion_tokens (includes reasoning budget),
  // does not support temperature. Budget must be large enough for internal reasoning + output.
  private buildBody(prompt: string, maxCompletionTokens: number) {
    return JSON.stringify({
      messages: [{ role: 'user', content: prompt }],
      max_completion_tokens: maxCompletionTokens,
    })
  }

  async generateProgrammeReport(data: ProgrammeReportInput): Promise<ProgrammeReport> {
    const { weekEnding, totalTowers, ragCounts, towers, topRaidds, overdueActions, atRiskMilestones, pulseComments } = data

    const towerSummaries = towers.map(t =>
      `- ${t.name} (${t.group}, ${t.phase || 'N/A'}): TWG ${t.twgScore ?? '—'}, TCS ${t.tcsScore ?? '—'}, RAG ${t.ragStatus ?? 'N/A'}` +
      (t.overdueActions > 0 ? `, ${t.overdueActions} overdue action(s)` : '') +
      (t.blockers.length > 0 ? `, BLOCKERS: ${t.blockers.slice(0, 2).join('; ')}` : '') +
      (t.narrative ? `\n  Narrative: ${t.narrative.slice(0, 200)}` : '')
    ).join('\n')

    const raiddSummary = topRaidds.map(r => `- [${r.type} / ${r.impact} impact] ${r.title} — ${r.towerName}`).join('\n') || 'None recorded'
    const actionsSummary = overdueActions.map(a => `- [${a.priority}] ${a.title} — ${a.towerName}`).join('\n') || 'None overdue'
    const milestoneSummary = atRiskMilestones.map(m => `- ${m.name} (${m.towerName}): ${m.status}`).join('\n') || 'None at risk'
    const pulseSummary = pulseComments.map(p => `- ${p.towerName} / ${p.track}: "${p.comment}"`).join('\n') || 'No pulse comments'

    const prompt = `You are a senior KT (Knowledge Transfer) Programme Manager analysing a live transition programme.
Your job is to produce an AI-generated executive briefing based on the data below.

=== PROGRAMME SNAPSHOT ===
Week Ending: ${weekEnding}
Total Towers: ${totalTowers}  |  GREEN: ${ragCounts.GREEN}  |  AMBER: ${ragCounts.AMBER}  |  RED: ${ragCounts.RED}

=== TOWER HEALTH (TWG & TCS scores, RAG, overdue actions, blockers, narratives) ===
${towerSummaries}

=== TOP OPEN RAIDD ITEMS (Risks / Assumptions / Issues / Dependencies / Decisions) ===
${raiddSummary}

=== OVERDUE ACTIONS ===
${actionsSummary}

=== AT-RISK / DELAYED / BLOCKED MILESTONES ===
${milestoneSummary}

=== PULSE SURVEY COMMENTS FROM TEAMS ===
${pulseSummary}

=== INSTRUCTIONS ===
Respond ONLY with a single valid JSON object using exactly these keys (no markdown fences, no extra text):
{
  "summary": "3-4 sentence overall programme health executive summary. State the RAG breakdown, highlight the most critical issue, and give one forward-looking statement.",
  "workingWell": "Bullet list (use • prefix, one per line) of 3-5 specific things working well across the programme based on the data.",
  "notWorking": "Bullet list (use • prefix, one per line) of 3-5 specific issues or gaps that are not working, with tower references where relevant.",
  "commonRisks": "Paragraph analysis of recurring risks and cross-tower patterns identified in the RAIDD log and narratives. Name specific towers and risk themes.",
  "priorityActions": "Numbered list (1. 2. 3. 4. 5.) of the top 5 priority actions leadership must take THIS WEEK, ordered by urgency. Be specific — name towers and owners where possible.",
  "forwardActions": "Bullet list (use • prefix, one per line) of 4-6 forward-looking recommendations for the next 2-4 weeks to improve KT progress across the programme."
}`

    const response = await fetch(this.url, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json', 'api-key': this.apiKey },
      body: this.buildBody(prompt, 8000),
    })

    if (!response.ok) {
      const err = await response.json().catch(() => ({}))
      throw new Error(`Azure OpenAI error ${response.status}: ${JSON.stringify(err)}`)
    }

    const result = await response.json()
    const text: string = result.choices?.[0]?.message?.content ?? ''

    // Strip possible markdown code fences the model might still add
    const cleaned = text.replace(/^```(?:json)?\s*/i, '').replace(/\s*```\s*$/, '').trim()
    try {
      return JSON.parse(cleaned) as ProgrammeReport
    } catch {
      // If JSON parse fails, put the raw text in summary so it's still visible
      return {
        summary: cleaned.slice(0, 1000) || 'AI response could not be parsed.',
        workingWell: '', notWorking: '', commonRisks: '', priorityActions: '', forwardActions: '',
      }
    }
  }

  async generateSummary(submission: Partial<WeeklySubmissionDTO>, towerName: string): Promise<string> {
    const prompt = `You are a KT Programme Manager writing a concise weekly executive summary for a single tower.

Tower: ${towerName}
Week Ending: ${submission.weekEnding}
Org: ${submission.org}
RAG Status: ${submission.ragStatus}
Total Score: ${submission.totalScore}/100
  Progress: ${submission.progressScore}/100 | Coverage: ${submission.coverageScore}/100
  Confidence: ${submission.confidenceScore}/100 | Operational: ${submission.operationalScore}/100 | Quality: ${submission.qualityScore}/100
Narrative: ${submission.narrative ?? 'None provided'}
Risks: ${(submission.risks ?? []).join(', ') || 'None'}
Blockers: ${(submission.blockers ?? []).join(', ') || 'None'}

Write 2-3 sentences: state the health status and score, call out the most important risk or achievement, and recommend one action. Be factual and direct.`

    const response = await fetch(this.url, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json', 'api-key': this.apiKey },
      body: this.buildBody(prompt, 3000),
    })

    if (!response.ok) throw new Error(`Azure OpenAI error: ${response.status}`)

    const data = await response.json()
    return data.choices?.[0]?.message?.content?.trim() ?? 'Summary unavailable.'
  }
}

export function getAIProvider(): AIProvider {
  const key = process.env.AZURE_OPENAI_API_KEY ?? process.env.AZURE_OPENAI_KEY
  if (key && process.env.AZURE_OPENAI_ENDPOINT) {
    return new AzureOpenAIProvider()
  }
  return new StubAIProvider()
}
